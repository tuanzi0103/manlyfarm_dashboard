import streamlit as st
import pandas as pd
import plotly.express as px
import math
import numpy as np
from services.db import get_db


def _safe_sum(df, col):
    if df is None or df.empty or col not in df.columns:
        return 0.0
    s = df[col]
    if pd.api.types.is_numeric_dtype(s):
        return float(pd.to_numeric(s, errors="coerce").sum(skipna=True))
    s = (
        s.astype(str)
        .str.replace(r"[^0-9\.\-]", "", regex=True)
        .replace("", pd.NA)
    )
    return float(pd.to_numeric(s, errors="coerce").sum(skipna=True) or 0.0)


def proper_round(x):
    """æ ‡å‡†çš„å››èˆäº”å…¥æ–¹æ³•ï¼Œ0.5æ€»æ˜¯å‘ä¸Šèˆå…¥"""
    if pd.isna(x):
        return x
    return math.floor(x + 0.5)


def persisting_multiselect(label, options, key, default=None):
    if key not in st.session_state:
        st.session_state[key] = default or []
    return st.multiselect(label, options, default=st.session_state[key], key=key)


# === ä¿®æ­£çš„èšåˆé€»è¾‘ - ç¡®ä¿barè®¡ç®—æ­£ç¡® ===
@st.cache_data
def get_high_level_data():
    db = get_db()

    # === totalï¼ˆæ—¥çº§ï¼‰ï¼šSUM(ROUND(Gross - Tax, 2))ï¼Œå†æ±‡æ€» ===
    daily_sql = """
    WITH transaction_totals AS (
        SELECT 
            date(Datetime) AS date,
            [Transaction ID] AS txn_id,
            SUM([Gross Sales]) AS total_gross_sales,
            SUM(COALESCE(CAST(REPLACE(REPLACE([Tax], '$', ''), ',', '') AS REAL), 0)) AS total_tax,
            SUM(Qty) AS total_qty
        FROM transactions
        GROUP BY date, [Transaction ID]
    )
    SELECT
        date,
        -- âœ… ä¿®æ­£ total é€»è¾‘ï¼šé€è¡Œ (Gross - Tax) ä¿ç•™ä¸¤ä½å°æ•°åæ±‚å’Œ
        SUM(ROUND(total_gross_sales - total_tax, 2)) AS net_sales_with_tax,
        SUM(total_gross_sales) AS gross_sales,
        SUM(total_tax) AS total_tax,
        COUNT(DISTINCT txn_id) AS transactions,
        CASE 
            WHEN COUNT(DISTINCT txn_id) > 0 
            THEN SUM(ROUND(total_gross_sales - total_tax, 2)) * 1.0 / COUNT(DISTINCT txn_id)
            ELSE 0 
        END AS avg_txn,
        SUM(total_qty) AS qty
    FROM transaction_totals
    GROUP BY date
    ORDER BY date;
    """

    # === categoryï¼ˆæ—¥çº§ï¼‰ï¼šSUM(ROUND(Net + Tax, 2)) ===
    category_sql = """
    WITH category_transactions AS (
        SELECT 
            date(Datetime) AS date,
            Category,
            [Transaction ID] AS txn_id,
            SUM([Net Sales]) AS cat_net_sales,
            SUM(COALESCE(CAST(REPLACE(REPLACE([Tax], '$', ''), ',', '') AS REAL), 0)) AS cat_tax,
            SUM([Gross Sales]) AS cat_gross,
            SUM(Qty) AS cat_qty
        FROM transactions
        GROUP BY date, Category, [Transaction ID]
    ),
    category_daily AS (
        SELECT
            date,
            Category,
            txn_id,
            SUM(ROUND(cat_net_sales + cat_tax, 2)) AS cat_total_with_tax,
            SUM(cat_net_sales) AS cat_net_sales,
            SUM(cat_tax) AS cat_tax,
            SUM(cat_gross) AS cat_gross,
            SUM(cat_qty) AS cat_qty
        FROM category_transactions
        GROUP BY date, Category, txn_id
    )
    SELECT
        date,
        Category,
        -- âœ… é€è¡Œä¿ç•™ä¸¤ä½å°æ•°åå†æ±‡æ€»
        SUM(cat_total_with_tax) AS net_sales_with_tax,
        SUM(cat_net_sales) AS net_sales,
        SUM(cat_tax) AS total_tax,
        COUNT(DISTINCT txn_id) AS transactions,
        CASE 
            WHEN COUNT(DISTINCT txn_id) > 0 
            THEN SUM(cat_total_with_tax) * 1.0 / COUNT(DISTINCT txn_id)
            ELSE 0 
        END AS avg_txn,
        SUM(cat_gross) AS gross,
        SUM(cat_qty) AS qty
    FROM category_daily
    GROUP BY date, Category
    ORDER BY date, Category;
    """

    daily = pd.read_sql(daily_sql, db)
    category = pd.read_sql(category_sql, db)

    if not daily.empty:
        daily["date"] = pd.to_datetime(daily["date"])
    if not category.empty:
        category["date"] = pd.to_datetime(category["date"])

    return daily, category


def _prepare_inventory_grouped(inv: pd.DataFrame):
    if inv is None or inv.empty:
        return pd.DataFrame(), None

    df = inv.copy()

    if "source_date" in df.columns:
        df["date"] = pd.to_datetime(df["source_date"], errors="coerce")
    else:
        return pd.DataFrame(), None

    # Category åˆ—
    if "Categories" in df.columns:
        df["Category"] = df["Categories"].astype(str)
    elif "Category" in df.columns:
        df["Category"] = df["Category"].astype(str)
    else:
        df["Category"] = "Unknown"

    # === ç”¨ catalogue ç°ç®— - åº”ç”¨æ–°çš„inventory valueè®¡ç®—é€»è¾‘ ===
    # 1. è¿‡æ»¤æ‰ Current Quantity Vie Market & Bar ä¸ºè´Ÿæ•°æˆ–0çš„è¡Œ
    df["Quantity"] = pd.to_numeric(df["Current Quantity Vie Market & Bar"], errors="coerce")
    mask = (df["Quantity"] > 0)  # åªä¿ç•™æ­£æ•°
    df = df[mask].copy()

    if df.empty:
        return pd.DataFrame(), None

    # 2. æŠŠ Default Unit Cost ä¸ºç©ºçš„å€¼è¡¥ä¸º0
    df["UnitCost"] = pd.to_numeric(df["Default Unit Cost"], errors="coerce").fillna(0)

    # 3. è®¡ç®— inventory value: Default Unit Cost * Current Quantity Vie Market & Bar
    df["Inventory Value"] = df["UnitCost"] * df["Quantity"]

    # å››èˆäº”å…¥ä¿ç•™æ•´æ•°
    df["Inventory Value"] = df["Inventory Value"].apply(lambda x: proper_round(x) if not pd.isna(x) else 0)

    # ä¿ç•™å…¶ä»–è®¡ç®—ï¼ˆå¦‚æœéœ€è¦ï¼‰
    df["Price"] = pd.to_numeric(df.get("Price", 0), errors="coerce").fillna(0)

    # ä¿®å¤ï¼šæ£€æŸ¥ TaxFlag åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤å€¼
    if "TaxFlag" not in df.columns:
        df["TaxFlag"] = "N"  # é»˜è®¤å€¼ï¼Œå‡è®¾ä¸å«ç¨

    def calc_retail(row):
        try:
            O, AA, tax = row["Price"], row["Quantity"], row["TaxFlag"]
            return (O / 11 * 10) * AA if tax == "Y" else O * AA
        except KeyError:
            # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œç›´æ¥è®¡ç®— Price * Quantity
            return row["Price"] * row["Quantity"]

    df["Retail Total"] = df.apply(calc_retail, axis=1)
    df["Profit"] = df["Retail Total"] - df["Inventory Value"]

    # èšåˆ
    g = (
        df.groupby(["date", "Category"], as_index=False)[["Inventory Value", "Profit"]]
        .sum(min_count=1)
    )

    latest_date = g["date"].max() if not g.empty else None
    return g, latest_date

# ç§»é™¤ @st.cache_data è£…é¥°å™¨ï¼Œå› ä¸ºå‡½æ•°ä¸­åŒ…å« widgets
def show_high_level(tx: pd.DataFrame, mem: pd.DataFrame, inv: pd.DataFrame):
    st.header("ğŸ“Š High Level Report")

    daily, category_tx = get_high_level_data()
    inv_grouped, inv_latest_date = _prepare_inventory_grouped(inv)

    if daily.empty:
        st.warning("No transaction data available. Please upload data first.")
        return

    # === ç‰¹å®šæ—¥æœŸé€‰æ‹© ===
    st.subheader("ğŸ“… Select Specific Date")
    col_date, _ = st.columns([1, 2])  # ç¬¬ä¸€ä¸ªåˆ—æ”¾é€‰æ‹©æ¡†ï¼Œç¬¬äºŒä¸ªç•™ç©ºæ‹‰çª„å®½åº¦
    with col_date:
        available_dates = sorted(daily["date"].dt.date.unique(), reverse=True)
        selected_date = st.selectbox("Choose a specific date to view data", available_dates)

    # è½¬æ¢ selected_date ä¸º Timestamp ç”¨äºæ¯”è¾ƒ
    selected_date_ts = pd.Timestamp(selected_date)

    # ç­›é€‰é€‰å®šæ—¥æœŸçš„æ•°æ®
    df_selected_date = daily[daily["date"] == selected_date_ts]

    today = pd.Timestamp.today().normalize()
    latest_date_tx = daily["date"].max()
    df_latest_tx = daily[daily["date"] == latest_date_tx]

    # === è®¡ç®—å®¢æˆ·æ•°é‡ ===
    def calculate_customer_count(tx_df, selected_date):
        if tx_df is None or tx_df.empty:
            return 0
        if 'Datetime' not in tx_df.columns:
            return 0

        tx_df = tx_df.copy()
        tx_df['Datetime'] = pd.to_datetime(tx_df['Datetime'], errors='coerce')
        tx_df = tx_df.dropna(subset=['Datetime'])
        if tx_df.empty:
            return 0

        selected_date_str = selected_date.strftime('%Y-%m-%d')
        daily_tx = tx_df[tx_df['Datetime'].dt.strftime('%Y-%m-%d') == selected_date_str]
        if daily_tx.empty:
            return 0

        if 'Card Brand' not in daily_tx.columns or 'PAN Suffix' not in daily_tx.columns:
            return 0

        filtered_tx = daily_tx.dropna(subset=['Card Brand', 'PAN Suffix'])
        if filtered_tx.empty:
            return 0

        filtered_tx['Card Brand'] = filtered_tx['Card Brand'].str.title()
        filtered_tx['PAN Suffix'] = filtered_tx['PAN Suffix'].astype(str).str.split('.').str[0]
        unique_customers = filtered_tx[['Card Brand', 'PAN Suffix']].drop_duplicates()

        return len(unique_customers)

    # === KPIï¼ˆäº¤æ˜“ï¼Œå£å¾„æŒ‰å°ç¥¨ï¼‰ ===
    # ä½¿ç”¨é€‰å®šæ—¥æœŸçš„æ•°æ® - ç¡®ä¿ä½¿ç”¨ net_sales_with_tax (Gross Sales - Tax)
    kpis_main = {
        "Daily Net Sales": proper_round(df_selected_date["net_sales_with_tax"].sum()),
        "Daily Transactions": df_selected_date["transactions"].sum(),
        "Number of Customers": calculate_customer_count(tx, selected_date),
        "Avg Transaction": df_selected_date["avg_txn"].mean(),
        "3M Avg": proper_round(daily["net_sales_with_tax"].rolling(90, min_periods=1).mean().iloc[-1]),
        "6M Avg": proper_round(daily["net_sales_with_tax"].rolling(180, min_periods=1).mean().iloc[-1]),
        "Items Sold": df_selected_date["qty"].sum(),
    }

    # === KPIï¼ˆåº“å­˜æ´¾ç”Ÿï¼Œcatalogue-onlyï¼‰ ===
    inv_value_latest = 0.0
    profit_latest = 0.0
    if inv_grouped is not None and not inv_grouped.empty and inv_latest_date is not None:
        sub = inv_grouped[inv_grouped["date"] == inv_latest_date]
        inv_value_latest = float(pd.to_numeric(sub["Inventory Value"], errors="coerce").sum())
        profit_latest = float(pd.to_numeric(sub["Profit"], errors="coerce").sum())

    st.markdown(f"### ğŸ“… Selected Date: {selected_date}")
    labels_values = list(kpis_main.items()) + [
        ("Inventory Value", inv_value_latest),
        ("Profit (Amount)", profit_latest),
    ]
    captions = {
        "Inventory Value": f"as of {pd.to_datetime(inv_latest_date).strftime('%Y-%m-%d') if inv_latest_date else '-'}",
        "Profit (Amount)": f"as of {pd.to_datetime(inv_latest_date).strftime('%Y-%m-%d') if inv_latest_date else '-'}",
    }

    for row in range(0, len(labels_values), 4):
        cols = st.columns(4)
        for i, col in enumerate(cols):
            idx = row + i
            if idx < len(labels_values):
                label, val = labels_values[idx]
                # ä½¿ç”¨æ ‡å‡†çš„å››èˆäº”å…¥æ–¹æ³•
                if pd.isna(val):
                    display = "-"
                else:
                    # å»æ‰ç¾å…ƒç¬¦å·ï¼Œå¹¶ä¸º Avg Transaction æ·»åŠ ä¸¤ä½å°æ•°
                    if label == "Avg Transaction":
                        display = f"${val:,.2f}"
                    elif label in ["Daily Net Sales", "3M Avg", "6M Avg", "Inventory Value", "Profit (Amount)"]:
                        display = f"${proper_round(val):,}"
                    else:
                        display = f"{proper_round(val):,}"
                with col:
                    st.markdown(f"<div style='font-size:28px; font-weight:600'>{display}</div>", unsafe_allow_html=True)
                    st.caption(label)
                    if label in captions:
                        st.caption(captions[label])

    st.markdown("---")

    # === äº¤äº’é€‰æ‹© ===
    st.subheader("ğŸ” Select Parameters")

    # ğŸ”¹ ç”¨ä¸‰åˆ—å¸ƒå±€ç¼©çŸ­ä¸‹æ‹‰æ¡†å®½åº¦
    col1, col2, col3 = st.columns([1, 1, 1])

    # === ç¬¬ä¸€åˆ—ï¼šæ—¶é—´èŒƒå›´ ===
    with col1:
        time_range_options = ["Custom dates", "WTD", "MTD", "YTD"]
        time_range = st.multiselect("Choose time range", time_range_options, key="hl_time")

    # === ç¬¬äºŒåˆ—ï¼šæ•°æ®ç±»å‹ ===
    with col2:
        data_options = [
            "Daily Net Sales", "Daily Transactions", "Avg Transaction", "3M Avg", "6M Avg",
            "Inventory Value", "Profit (Amount)", "Items Sold"
        ]
        data_sel = persisting_multiselect("Choose data type", data_options, key="hl_data")

    # === ç¬¬ä¸‰åˆ—ï¼šåˆ†ç±» ===
    with col3:
        bar_cats = {"Cafe Drinks", "Smoothie Bar", "Soups", "Sweet Treats", "Wraps & Salads"}

        if category_tx is None or category_tx.empty:
            st.info("No category breakdown available.")
            return

        all_cats_tx = sorted(category_tx["Category"].fillna("Unknown").unique().tolist())

        # è°ƒæ•´é€‰é¡¹é¡ºåºï¼šbar, retail, total åœ¨æœ€ä¸Šé¢ï¼Œç„¶åæ˜¯å…¶ä»–ç±»åˆ«
        special_cats = ["bar", "retail", "total"]
        all_cats_extended = special_cats + sorted([c for c in all_cats_tx if c not in special_cats])

        cats_sel = persisting_multiselect("Choose categories", all_cats_extended, key="hl_cats")

    # === è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´é€‰æ‹© ===
    custom_dates_selected = False
    t1 = None
    t2 = None

    if "Custom dates" in time_range:
        custom_dates_selected = True
        # ğŸ”¹ ä¿®å¤1ï¼šä½¿ç”¨ä¸ä¸Šé¢ä¸‰åˆ—å¸ƒå±€ç›¸åŒé•¿åº¦çš„åˆ—å¸ƒå±€ï¼Œä¸ sales_report.py ä¿æŒä¸€è‡´
        st.markdown("#### ğŸ“… Custom Date Range")
        col_from, col_to, _ = st.columns([1, 1, 1])  # æ”¹ä¸ºä¸‰åˆ—å¸ƒå±€
        with col_from:
            t1 = st.date_input(
                "From",
                value=pd.Timestamp.today().normalize() - pd.Timedelta(days=7),
                key="date_from"
            )
        with col_to:
            t2 = st.date_input(
                "To",
                value=pd.Timestamp.today().normalize(),
                key="date_to"
            )

    # ä¿®å¤1ï¼šä¿®æ­£æ¡ä»¶åˆ¤æ–­é€»è¾‘
    has_time_range = bool(time_range)
    has_data_sel = bool(data_sel)
    has_cats_sel = bool(cats_sel)

    # å¯¹äº Custom datesï¼Œéœ€è¦ç¡®ä¿æ—¥æœŸå·²é€‰æ‹©
    if "Custom dates" in time_range:
        has_valid_custom_dates = (t1 is not None and t2 is not None)
    else:
        has_valid_custom_dates = True

    if has_time_range and has_data_sel and has_cats_sel and has_valid_custom_dates:
        # é¦–å…ˆè·å–å®Œæ•´çš„æ•°æ®ç”¨äºè®¡ç®—æ»šåŠ¨å¹³å‡
        daily_full = daily.copy()
        grouped_tx_full = category_tx.copy()

        # è·å–å½“å‰æ—¥æœŸ
        today = pd.Timestamp.today().normalize()

        # è®¡ç®—æ—¶é—´èŒƒå›´ç­›é€‰æ¡ä»¶
        start_of_week = today - pd.Timedelta(days=today.weekday())
        start_of_month = today.replace(day=1)
        start_of_year = today.replace(month=1, day=1)

        # åº”ç”¨æ—¶é—´èŒƒå›´ç­›é€‰åˆ°dailyæ•°æ®
        daily_filtered = daily.copy()
        grouped_tx = category_tx.copy()

        if "WTD" in time_range:
            daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_week]
            grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_week]
        if "MTD" in time_range:
            daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_month]
            grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_month]
        if "YTD" in time_range:
            daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_year]
            grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_year]
        if custom_dates_selected and t1 and t2:
            t1_ts = pd.to_datetime(t1)
            t2_ts = pd.to_datetime(t2)
            daily_filtered = daily_filtered[
                (daily_filtered["date"] >= t1_ts) & (daily_filtered["date"] <= t2_ts)]
            grouped_tx = grouped_tx[
                (grouped_tx["date"] >= t1_ts) & (grouped_tx["date"] <= t2_ts)]

        grouped_inv = inv_grouped.copy()
        # å¯¹åº“å­˜æ•°æ®åº”ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´ç­›é€‰
        if not grouped_inv.empty:
            if "WTD" in time_range:
                grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_week]
            if "MTD" in time_range:
                grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_month]
            if "YTD" in time_range:
                grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_year]
            if custom_dates_selected and t1 and t2:
                grouped_inv = grouped_inv[
                    (grouped_inv["date"] >= pd.to_datetime(t1)) & (grouped_inv["date"] <= pd.to_datetime(t2))]

        small_cats = [c for c in cats_sel if c not in ("bar", "retail", "total")]
        parts_tx = []

        if small_cats:
            parts_tx.append(grouped_tx[grouped_tx["Category"].isin(small_cats)])

        # === åº”ç”¨æ–°çš„è®¡ç®—é€»è¾‘ ===
        if "bar" in cats_sel:
            bar_cats = {"Cafe Drinks", "Smoothie Bar", "Soups", "Sweet Treats", "Wraps & Salads"}
            bar_tx = grouped_tx[grouped_tx["Category"].isin(bar_cats)].copy()
            if not bar_tx.empty:
                # ä¿®æ”¹ï¼šå…ˆå°†äº”ç±»æ•°æ®æŒ‰æ—¥æœŸèšåˆï¼Œå†è®¾ç½®ä¸ºbar
                bar_tx_aggregated = bar_tx.groupby("date").agg({
                    "net_sales_with_tax": "sum",
                    "net_sales": "sum",
                    "total_tax": "sum",
                    "transactions": "sum",
                    "avg_txn": "mean",
                    "gross": "sum",
                    "qty": "sum"
                }).reset_index()
                bar_tx_aggregated["Category"] = "bar"
                parts_tx.append(bar_tx_aggregated)

        if "retail" in cats_sel:
            retail_cats = {"Retail"}
            retail_tx = grouped_tx[grouped_tx["Category"].isin(retail_cats)].copy()
            if not retail_tx.empty:
                retail_tx["Category"] = "retail"
                parts_tx.append(retail_tx)

        if "total" in cats_sel:
            total_tx = daily_filtered.copy()
            total_tx["Category"] = "total"
            parts_tx.append(total_tx)

        if not parts_tx:
            st.warning("No data for selected categories.")
            return

        df_plot = pd.concat(parts_tx, ignore_index=True)

        # === æ•°æ®æ˜ å°„ ===
        data_map = {
            "Daily Net Sales": "net_sales_with_tax",
            "Daily Transactions": "transactions",
            "Avg Transaction": "avg_txn",
            "3M Avg": "net_sales_with_tax",
            "6M Avg": "net_sales_with_tax",
            "Items Sold": "qty",
        }

        # å¤„ç†æ»šåŠ¨å¹³å‡
        if "3M Avg" in data_sel or "6M Avg" in data_sel:
            # ä¸ºæ¯ä¸ªç±»åˆ«è®¡ç®—æ»šåŠ¨å¹³å‡
            df_plot_rolling = df_plot.copy()
            df_plot_rolling = df_plot_rolling.sort_values(["Category", "date"])

            # ä½¿ç”¨å®Œæ•´æ•°æ®è®¡ç®—æ»šåŠ¨å¹³å‡
            df_full_rolling = pd.concat([
                # ä¿®æ”¹ï¼šbarç±»åˆ«éœ€è¦å…ˆèšåˆäº”ç±»æ•°æ®
                grouped_tx_full[grouped_tx_full["Category"].isin(bar_cats)].groupby("date").agg({
                    "net_sales_with_tax": "sum",
                    "net_sales": "sum",
                    "total_tax": "sum",
                    "transactions": "sum",
                    "avg_txn": "mean",
                    "gross": "sum",
                    "qty": "sum"
                }).reset_index().assign(Category="bar") if cat == "bar" else
                grouped_tx_full.assign(Category="retail") if cat == "retail" else
                daily_full.assign(Category="total") if cat == "total" else
                grouped_tx_full[grouped_tx_full["Category"] == cat].copy()
                for cat in cats_sel
            ], ignore_index=True)

            df_full_rolling = df_full_rolling.sort_values(["Category", "date"])

            # è®¡ç®—æ»šåŠ¨å¹³å‡
            window_3m = 90
            window_6m = 180

            df_full_rolling["3M Avg"] = df_full_rolling.groupby("Category")["net_sales_with_tax"].transform(
                lambda x: x.rolling(window_3m, min_periods=1).mean()
            )
            df_full_rolling["6M Avg"] = df_full_rolling.groupby("Category")["net_sales_with_tax"].transform(
                lambda x: x.rolling(window_6m, min_periods=1).mean()
            )

            # åº”ç”¨æ—¶é—´èŒƒå›´ç­›é€‰åˆ°æ»šåŠ¨å¹³å‡æ•°æ®
            df_full_rolling_filtered = df_full_rolling.copy()
            if "WTD" in time_range:
                df_full_rolling_filtered = df_full_rolling_filtered[df_full_rolling_filtered["date"] >= start_of_week]
            if "MTD" in time_range:
                df_full_rolling_filtered = df_full_rolling_filtered[df_full_rolling_filtered["date"] >= start_of_month]
            if "YTD" in time_range:
                df_full_rolling_filtered = df_full_rolling_filtered[df_full_rolling_filtered["date"] >= start_of_year]
            if custom_dates_selected and t1 and t2:
                df_full_rolling_filtered = df_full_rolling_filtered[
                    (df_full_rolling_filtered["date"] >= pd.to_datetime(t1)) &
                    (df_full_rolling_filtered["date"] <= pd.to_datetime(t2))
                    ]

            # åˆå¹¶æ»šåŠ¨å¹³å‡æ•°æ®åˆ°ä¸»æ•°æ®æ¡†
            df_plot = df_plot.merge(
                df_full_rolling_filtered[["date", "Category", "3M Avg", "6M Avg"]],
                on=["date", "Category"], how="left"
            )

        # å¤„ç†åº“å­˜æ•°æ®
        if "Inventory Value" in data_sel or "Profit (Amount)" in data_sel:
            if grouped_inv is not None and not grouped_inv.empty:
                # ç¡®ä¿åº“å­˜æ•°æ®æœ‰ç›¸åŒçš„åˆ—ç»“æ„
                grouped_inv_plot = grouped_inv.copy()
                # é‡å‘½ååˆ—ä»¥åŒ¹é…äº¤æ˜“æ•°æ®
                grouped_inv_plot = grouped_inv_plot.rename(columns={
                    "Inventory Value": "inventory_value",
                    "Profit": "profit_amount"
                })
                # æ·»åŠ ç¼ºå¤±çš„åˆ—
                for col in ["net_sales_with_tax", "transactions", "avg_txn", "qty"]:
                    grouped_inv_plot[col] = 0

                # å¦‚æœé€‰æ‹©äº†åº“å­˜ç›¸å…³çš„æ•°æ®ï¼Œå°†åº“å­˜æ•°æ®åˆå¹¶åˆ°ä¸»æ•°æ®æ¡†
                if small_cats:
                    inv_small = grouped_inv_plot[grouped_inv_plot["Category"].isin(small_cats)]
                    df_plot = pd.concat([df_plot, inv_small], ignore_index=True)

                if "bar" in cats_sel:
                    bar_inv = grouped_inv_plot[grouped_inv_plot["Category"].isin(bar_cats)].copy()
                    if not bar_inv.empty:
                        bar_inv["Category"] = "bar"
                        df_plot = pd.concat([df_plot, bar_inv], ignore_index=True)

                if "retail" in cats_sel:
                    retail_inv = grouped_inv_plot[grouped_inv_plot["Category"].isin(["Retail"])].copy()
                    if not retail_inv.empty:
                        retail_inv["Category"] = "retail"
                        df_plot = pd.concat([df_plot, retail_inv], ignore_index=True)

                if "total" in cats_sel:
                    total_inv = grouped_inv_plot.copy()
                    total_inv_sum = total_inv.groupby("date").agg({
                        "inventory_value": "sum",
                        "profit_amount": "sum"
                    }).reset_index()
                    total_inv_sum["Category"] = "total"
                    # æ·»åŠ ç¼ºå¤±çš„åˆ—
                    for col in ["net_sales_with_tax", "transactions", "avg_txn", "qty"]:
                        total_inv_sum[col] = 0
                    df_plot = pd.concat([df_plot, total_inv_sum], ignore_index=True)

        # ç¡®ä¿æ•°æ®åˆ—å­˜åœ¨
        for col in data_map.values():
            if col not in df_plot.columns:
                df_plot[col] = 0

        # æ·»åŠ åº“å­˜æ•°æ®åˆ—
        if "inventory_value" not in df_plot.columns:
            df_plot["inventory_value"] = 0
        if "profit_amount" not in df_plot.columns:
            df_plot["profit_amount"] = 0

        # æ‰©å±•æ•°æ®æ˜ å°„
        data_map_extended = {
            **data_map,
            "Inventory Value": "inventory_value",
            "Profit (Amount)": "profit_amount"
        }

        # ğŸ”¹ ä¿®å¤2ï¼šæŠŠæ‰€æœ‰data typeéƒ½å±•ç¤ºåœ¨åŒä¸€ä¸ªæŠ˜çº¿å›¾é‡Œ
        if data_sel:
            # åˆ›å»ºèåˆæ•°æ®æ¡†ï¼Œå°†æ‰€æœ‰é€‰ä¸­çš„æ•°æ®åˆ—åˆå¹¶åˆ°ä¸€ä¸ªå›¾ä¸­
            melted_dfs = []

            for data_type in data_sel:
                if data_type not in data_map_extended:
                    continue

                col_name = data_map_extended[data_type]
                if col_name not in df_plot.columns:
                    continue

                # ä¸ºæ¯ä¸ªæ•°æ®ç±»å‹åˆ›å»ºå­æ•°æ®æ¡†
                temp_df = df_plot[["date", "Category", col_name]].copy()
                temp_df = temp_df.rename(columns={col_name: "value"})
                temp_df["data_type"] = data_type

                # è¿‡æ»¤æ‰æ²¡æœ‰æ•°æ®çš„è¡Œ
                temp_df = temp_df[temp_df["value"].notna() & (temp_df["value"] != 0)]

                if not temp_df.empty:
                    melted_dfs.append(temp_df)

            if melted_dfs:
                # åˆå¹¶æ‰€æœ‰æ•°æ®
                combined_df = pd.concat(melted_dfs, ignore_index=True)

                # åˆ›å»ºå›¾è¡¨ - ä½¿ç”¨ data_type å’Œ Category çš„ç»„åˆä½œä¸ºçº¿æ¡
                combined_df["series"] = combined_df["Category"] + " - " + combined_df["data_type"]

                fig = px.line(
                    combined_df,
                    x="date",
                    y="value",
                    color="series",
                    title="All Selected Data Types by Category",
                    labels={"date": "Date", "value": "Value", "series": "Series"}
                )

                fig.update_layout(
                    xaxis=dict(tickformat="%Y-%m-%d"),
                    hovermode="x unified",
                    height=600
                )

                st.plotly_chart(fig, use_container_width=True)

                # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                with st.expander("View combined data for all selected types"):
                    display_df = combined_df.copy()
                    display_df["date"] = display_df["date"].dt.strftime("%Y-%m-%d")
                    display_df = display_df.rename(columns={
                        "date": "Date",
                        "Category": "Category",
                        "data_type": "Data Type",
                        "value": "Value"
                    })
                    display_df = display_df.sort_values(["Date", "Category", "Data Type"])
                    st.dataframe(display_df, use_container_width=True)
            else:
                st.warning("No data available for the selected data types.")